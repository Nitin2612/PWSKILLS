{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theoretical\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KVFu16j7uRD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is a Decision Tree, and how does it work?"
      ],
      "metadata": {
        "id": "iHhgsawduaHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ³ Decision Tree - Explained\n",
        "\n",
        "A **Decision Tree** is a supervised machine learning algorithm used for both **classification** and **regression** tasks. It works by learning decision rules inferred from data features.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Key Concepts\n",
        "\n",
        "- **Root Node**: The topmost node representing the entire dataset, which gets split.\n",
        "- **Decision Nodes**: Nodes where the dataset is split based on a feature.\n",
        "- **Leaf Nodes (Terminal Nodes)**: Nodes that contain the final output class or value.\n",
        "- **Branches**: Arrows connecting nodes, showing the flow of decision logic.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  How Does It Work?\n",
        "\n",
        "1. **Start at the root node**.\n",
        "2. **Select the best feature** to split the data using a criterion (like Gini Index or Information Gain).\n",
        "3. **Split the dataset** into subsets based on that feature.\n",
        "4. **Repeat the process** recursively for each subset until:\n",
        "   - All data points belong to the same class, or\n",
        "   - Maximum depth is reached, or\n",
        "   - No more features are available.\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Common Splitting Criteria\n",
        "\n",
        "- **Gini Impurity**: Measures the probability of misclassification.\n",
        "- **Entropy / Information Gain**: Measures the information gained from a split.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ˆ Example (Classification)\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Create model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(12,8))\n",
        "tree.plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WO95SXB3uiIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What are impurity measures in Decision Trees?"
      ],
      "metadata": {
        "id": "WTZb2mY9u29V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§® Impurity Measures in Decision Trees\n",
        "\n",
        "In Decision Trees, **impurity measures** are used to determine how \"mixed\" the classes are in a node. The goal of a split is to reduce impurity â€” i.e., make child nodes more \"pure\" (containing mostly one class).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Why Use Impurity Measures?\n",
        "\n",
        "When building a tree, the algorithm evaluates potential splits using impurity measures to choose the feature and threshold that **best separates the data**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š Common Impurity Measures\n",
        "\n",
        "### 1. **Gini Impurity**\n",
        "\n",
        "- Measures the likelihood of an incorrect classification of a randomly chosen element.\n",
        "- Formula:\n",
        "  \\[\n",
        "  Gini = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "  \\]\n",
        "  Where \\( p_i \\) is the probability of class \\( i \\) in a node.\n",
        "\n",
        "- **Range**: 0 (pure) to ~0.5 (impure for binary classification)\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Entropy (Information Gain)**\n",
        "\n",
        "- Measures the level of disorder or unpredictability.\n",
        "- Formula:\n",
        "  \\[\n",
        "  Entropy = -\\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "  \\]\n",
        "\n",
        "- A node with only one class has entropy = 0.\n",
        "- **Information Gain** = Entropy(Parent) - Weighted Average(Entropy of Children)\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Classification Error (Less Common)**\n",
        "\n",
        "- Simpler but less sensitive to changes in class distribution.\n",
        "- Formula:\n",
        "  \\[\n",
        "  Error = 1 - \\max(p_i)\n",
        "  \\]\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Comparison\n",
        "\n",
        "| Criterion             | Formula                        | Best for             | Range       |\n",
        "|----------------------|--------------------------------|----------------------|-------------|\n",
        "| Gini Impurity         | \\(1 - \\sum p_i^2\\)             | CART (default in `sklearn`) | 0 to 0.5    |\n",
        "| Entropy               | \\(-\\sum p_i \\log_2(p_i)\\)      | ID3 Algorithm        | 0 to 1      |\n",
        "| Classification Error  | \\(1 - \\max(p_i)\\)              | Rarely used          | 0 to 1      |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¡ Example in Code\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Gini (default)\n",
        "clf_gini = DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "# Entropy\n",
        "clf_entropy = DecisionTreeClassifier(criterion='entropy')\n"
      ],
      "metadata": {
        "id": "XWHe9ZtIvBy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. What is the mathematical formula for Gini Impurity?"
      ],
      "metadata": {
        "id": "cDGkG0CavIAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§® Gini Impurity - Mathematical Formula\n",
        "\n",
        "Gini Impurity is a measure of how often a randomly chosen element would be incorrectly classified if it was randomly labeled according to the distribution of labels in the node.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Formula\n",
        "\n",
        "\\[\n",
        "Gini(p) = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( C \\) = Number of classes\n",
        "- \\( p_i \\) = Proportion of samples belonging to class \\( i \\) at a given node\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example\n",
        "\n",
        "If a node contains:\n",
        "- 4 samples of Class A\n",
        "- 6 samples of Class B\n",
        "\n",
        "Then:\n",
        "- \\( p_A = \\frac{4}{10} = 0.4 \\)\n",
        "- \\( p_B = \\frac{6}{10} = 0.6 \\)\n",
        "\n",
        "\\[\n",
        "Gini = 1 - (0.4^2 + 0.6^2) = 1 - (0.16 + 0.36) = 1 - 0.52 = 0.48\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Interpretation\n",
        "\n",
        "- **Gini = 0** â†’ Perfectly pure (all elements belong to one class)\n",
        "- **Higher Gini** â†’ More mixed classes\n",
        "\n",
        "---\n",
        "\n",
        "> ðŸ“ **Note**: Gini is used by default in CART (Classification and Regression Tree) algorithms, such as `sklearn.tree.DecisionTreeClassifier`.\n"
      ],
      "metadata": {
        "id": "75cWPHlvvQ7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. What is the mathematical formula for Entropy?"
      ],
      "metadata": {
        "id": "U6CWcjJ7vWFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¢ Entropy - Mathematical Formula\n",
        "\n",
        "**Entropy** is a measure of impurity or disorder in a set. In decision trees, it quantifies the uncertainty in the data at a node.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Formula\n",
        "\n",
        "\\[\n",
        "Entropy(p) = - \\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( C \\) = Number of classes\n",
        "- \\( p_i \\) = Proportion of instances belonging to class \\( i \\)\n",
        "- The base of the logarithm is **2** because we measure entropy in **bits**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example\n",
        "\n",
        "If a node contains:\n",
        "- 5 samples of Class A\n",
        "- 5 samples of Class B\n",
        "\n",
        "Then:\n",
        "- \\( p_A = 0.5 \\), \\( p_B = 0.5 \\)\n",
        "\n",
        "\\[\n",
        "Entropy = - (0.5 \\log_2(0.5) + 0.5 \\log_2(0.5)) \\\\\n",
        "= - (0.5 \\times -1 + 0.5 \\times -1) = 1.0\n",
        "\\]\n",
        "\n",
        "ðŸ‘‰ This is **maximum entropy** (maximum disorder)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Interpretation\n",
        "\n",
        "- **Entropy = 0** â†’ Pure node (all samples belong to one class)\n",
        "- **Higher Entropy** â†’ More mixed or uncertain distribution\n",
        "\n",
        "---\n",
        "\n",
        "> ðŸ“ **Note**: Entropy is used in the ID3 algorithm and is often compared with **Gini Impurity**. Both aim to find the best feature split by reducing impurity.\n"
      ],
      "metadata": {
        "id": "PbgiA3sHvdzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5.  What is Information Gain, and how is it used in Decision Trees?"
      ],
      "metadata": {
        "id": "YA96Z63zvqRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¡ Information Gain in Decision Trees\n",
        "\n",
        "**Information Gain (IG)** is a key concept used to decide **which feature to split on** at each step in building a decision tree. It measures the **reduction in entropy** after a dataset is split on an attribute.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Definition\n",
        "\n",
        "Information Gain is the **difference between the entropy of the parent node** and the **weighted average entropy of child nodes**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Formula\n",
        "\n",
        "\\[\n",
        "IG(D, A) = Entropy(D) - \\sum_{v \\in Values(A)} \\frac{|D_v|}{|D|} \\cdot Entropy(D_v)\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( D \\) = Dataset\n",
        "- \\( A \\) = Feature/attribute\n",
        "- \\( Values(A) \\) = Unique values of feature \\( A \\)\n",
        "- \\( D_v \\) = Subset of \\( D \\) where feature \\( A \\) has value \\( v \\)\n",
        "- \\( |D| \\) = Total number of instances in the dataset\n",
        "- \\( |D_v| \\) = Number of instances in subset \\( D_v \\)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  How It's Used in Decision Trees\n",
        "\n",
        "1. At each node, calculate the **Information Gain** for all features.\n",
        "2. Select the feature that gives the **highest Information Gain**.\n",
        "3. Split the node using that feature.\n",
        "4. Repeat recursively for the child nodes.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example\n",
        "\n",
        "Imagine you have a dataset \\( D \\) with two features: \"Weather\" and \"Play Tennis\".\n",
        "\n",
        "- Total Entropy (before split): 0.94\n",
        "- After splitting on \"Weather\":\n",
        "  - Subset 1 (Sunny): Entropy = 0.97, size = 5\n",
        "  - Subset 2 (Rainy): Entropy = 0.86, size = 9\n",
        "\n",
        "\\[\n",
        "IG(Weather) = 0.94 - \\left( \\frac{5}{14} \\cdot 0.97 + \\frac{9}{14} \\cdot 0.86 \\right) \\\\\n",
        "= 0.94 - (0.346 + 0.553) = 0.94 - 0.899 = 0.041\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Interpretation\n",
        "\n",
        "- **High IG**: Feature provides good separation between classes â†’ useful for splitting\n",
        "- **Low IG**: Feature does not reduce uncertainty â†’ not useful\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Note\n",
        "\n",
        "- Information Gain is used in **ID3 algorithm**.\n",
        "- For continuous features, a threshold is selected that gives the maximum IG.\n",
        "\n",
        "---\n",
        "\n",
        "> ðŸš€ **Tip**: While Information Gain uses entropy, **Gini Impurity** is often preferred in practice for its computational efficiency (used in CART).\n"
      ],
      "metadata": {
        "id": "8xZs7TU1vy7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. What is the difference between Gini Impurity and Entropy?"
      ],
      "metadata": {
        "id": "pyrCWh-cv6sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âš–ï¸ Gini Impurity vs Entropy in Decision Trees\n",
        "\n",
        "Both **Gini Impurity** and **Entropy** are impurity measures used to build decision trees. They help determine the best feature to split the dataset at each step by measuring how \"pure\" or \"impure\" a node is.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Key Differences\n",
        "\n",
        "| Feature               | Gini Impurity                                      | Entropy (Information Gain)                       |\n",
        "|----------------------|----------------------------------------------------|--------------------------------------------------|\n",
        "| **Definition**        | Measures the probability of incorrect classification | Measures the amount of information (disorder)     |\n",
        "| **Formula**           | \\( Gini = 1 - \\sum p_i^2 \\)                        | \\( Entropy = - \\sum p_i \\log_2(p_i) \\)           |\n",
        "| **Used in**           | CART Algorithm (Classification And Regression Trees) | ID3 Algorithm                                    |\n",
        "| **Range**             | 0 (pure) to 0.5 (for binary classification)        | 0 (pure) to 1 (maximum disorder in binary)       |\n",
        "| **Computational Cost**| Faster (no logarithms)                            | Slightly slower (uses log base 2)                |\n",
        "| **Behavior**          | Tends to isolate the most frequent class          | Tends to produce more balanced splits            |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Intuition\n",
        "\n",
        "- **Gini** focuses more on classifying the most frequent class.\n",
        "- **Entropy** is more sensitive to class distribution and focuses on overall uncertainty.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example Comparison\n",
        "\n",
        "For a binary node with:\n",
        "- Class A: 4 instances\n",
        "- Class B: 6 instances\n",
        "\n",
        "### Gini:\n",
        "\\[\n",
        "Gini = 1 - (0.4^2 + 0.6^2) = 0.48\n",
        "\\]\n",
        "\n",
        "### Entropy:\n",
        "\\[\n",
        "Entropy = - (0.4 \\log_2(0.4) + 0.6 \\log_2(0.6)) \\approx 0.971\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ Which One Should You Use?\n",
        "\n",
        "- **Gini** is faster and is the **default in `scikit-learn`**.\n",
        "- **Entropy** is more informative for understanding uncertainty.\n",
        "- In practice, **both often lead to similar trees**.\n",
        "\n",
        "---\n",
        "\n",
        "> âœ… **Tip**: Try both for your specific dataset and compare results â€” performance differences are usually small but can vary depending on data characteristics.\n"
      ],
      "metadata": {
        "id": "sdk5m2UnwQSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. What is the mathematical explanation behind Decision Trees?"
      ],
      "metadata": {
        "id": "Xw6XGOwcwUw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“ Mathematical Explanation of Decision Trees\n",
        "\n",
        "A **Decision Tree** is a supervised learning algorithm that builds a **tree-like model** of decisions using **recursive partitioning** of the feature space based on **impurity measures** like Gini or Entropy.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Objective\n",
        "\n",
        "At each node, the algorithm chooses the **best feature and threshold** that results in the **greatest reduction in impurity**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Step-by-Step Mathematical Flow\n",
        "\n",
        "### 1. **Calculate Node Impurity**\n",
        "\n",
        "#### For Gini Impurity:\n",
        "\\[\n",
        "Gini(D) = 1 - \\sum_{i=1}^{C} p_i^2\n",
        "\\]\n",
        "\n",
        "#### For Entropy:\n",
        "\\[\n",
        "Entropy(D) = -\\sum_{i=1}^{C} p_i \\log_2(p_i)\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( D \\) = Current dataset at a node\n",
        "- \\( C \\) = Number of classes\n",
        "- \\( p_i \\) = Proportion of class \\( i \\) in \\( D \\)\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Split the Data on Each Feature**\n",
        "\n",
        "For each feature \\( A \\), try all possible thresholds \\( t \\), and partition the dataset into:\n",
        "\n",
        "- \\( D_{left} = \\{x \\in D \\mid x[A] \\leq t\\} \\)\n",
        "- \\( D_{right} = \\{x \\in D \\mid x[A] > t\\} \\)\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Calculate Weighted Impurity After Split**\n",
        "\n",
        "Let:\n",
        "- \\( N \\) = Total samples in \\( D \\)\n",
        "- \\( N_{left} = |D_{left}| \\)\n",
        "- \\( N_{right} = |D_{right}| \\)\n",
        "\n",
        "Then:\n",
        "\n",
        "#### For Gini:\n",
        "\\[\n",
        "Gini_{split}(A, t) = \\frac{N_{left}}{N} \\cdot Gini(D_{left}) + \\frac{N_{right}}{N} \\cdot Gini(D_{right})\n",
        "\\]\n",
        "\n",
        "#### For Entropy:\n",
        "\\[\n",
        "Entropy_{split}(A, t) = \\frac{N_{left}}{N} \\cdot Entropy(D_{left}) + \\frac{N_{right}}{N} \\cdot Entropy(D_{right})\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Calculate Information Gain (If Using Entropy)**\n",
        "\n",
        "\\[\n",
        "Information\\ Gain = Entropy(D) - Entropy_{split}(A, t)\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Choose the Best Split**\n",
        "\n",
        "- For Gini: Choose \\( (A, t) \\) that **minimizes** \\( Gini_{split} \\)\n",
        "- For Entropy: Choose \\( (A, t) \\) that **maximizes** Information Gain\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Recursively Repeat** the Process\n",
        "\n",
        "- Stop when:\n",
        "  - All samples belong to the same class (pure node)\n",
        "  - No more features left\n",
        "  - A stopping criterion is met (like max depth or min samples)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Final Prediction\n",
        "\n",
        "- Classification: Most frequent class in the leaf node\n",
        "- Regression: Mean or median of the target values in the leaf node\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Summary\n",
        "\n",
        "| Component         | Math Used                                 |\n",
        "|------------------|--------------------------------------------|\n",
        "| Splitting         | Impurity measures (Gini, Entropy)         |\n",
        "| Evaluation        | Weighted impurity / Information Gain       |\n",
        "| Decision Making   | Optimal feature and threshold selection    |\n",
        "| Recursion         | Tree building through divide and conquer  |\n",
        "\n",
        "---\n",
        "\n",
        "> ðŸ’¡ **Tip**: Decision Trees are prone to overfitting. Use **pruning**, **max depth**, or ensemble methods like **Random Forests** to improve generalization.\n"
      ],
      "metadata": {
        "id": "2aB3cNhbwb6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. What is Pre-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "aLJcNsh2wjzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‚ï¸ Pre-Pruning in Decision Trees\n",
        "\n",
        "**Pre-Pruning** (also called **Early Stopping**) is a technique used to prevent **overfitting** in decision trees by **halting the tree-building process early**â€”before the tree becomes too complex.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Objective\n",
        "\n",
        "To **control the growth** of the decision tree by applying stopping criteria **before** the tree fully classifies the training data, thus improving **generalization performance**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Common Pre-Pruning Techniques\n",
        "\n",
        "1. **Maximum Depth (`max_depth`)**\n",
        "   - Limits how deep the tree can grow.\n",
        "   - Prevents overfitting to noise in deep branches.\n",
        "\n",
        "2. **Minimum Samples per Split (`min_samples_split`)**\n",
        "   - A node must have at least this many samples to be split.\n",
        "   - Stops splitting on small, potentially noisy subsets.\n",
        "\n",
        "3. **Minimum Samples per Leaf (`min_samples_leaf`)**\n",
        "   - Each leaf node must contain at least this many samples.\n",
        "   - Prevents creation of small leaf nodes with overfitting risk.\n",
        "\n",
        "4. **Maximum Number of Leaves (`max_leaf_nodes`)**\n",
        "   - Limits the total number of leaf nodes in the tree.\n",
        "   - Ensures a simpler and more interpretable tree.\n",
        "\n",
        "5. **Minimum Impurity Decrease**\n",
        "   - Splitting continues only if the impurity (e.g., Gini or Entropy) decreases by a minimum amount.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Example in Scikit-learn\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Apply pre-pruning\n",
        "clf = DecisionTreeClassifier(\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "cyeFaJlIwqiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9. What is Post-Pruning in Decision Trees?"
      ],
      "metadata": {
        "id": "3sRDGZ3Ew7aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ³âœ‚ï¸ Post-Pruning in Decision Trees\n",
        "\n",
        "**Post-Pruning** (also called **Cost Complexity Pruning**) is a technique used to **simplify a fully grown decision tree** by **removing branches that do not provide significant predictive power**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Objective\n",
        "\n",
        "To reduce **overfitting** and improve **generalization** by trimming parts of the tree that are too specific to the training data.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”„ How Post-Pruning Works\n",
        "\n",
        "1. Grow the tree **fully** (until pure leaf nodes or stopping criteria).\n",
        "2. Evaluate subtrees or branches using **cross-validation** or **validation data**.\n",
        "3. **Remove branches** that do not improve the model's accuracy significantly.\n",
        "4. Replace those branches with **leaf nodes**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Common Post-Pruning Technique\n",
        "\n",
        "### Cost Complexity Pruning (used in `scikit-learn`)\n",
        "\n",
        "- Introduces a **penalty term** \\( \\alpha \\) for the complexity (number of leaf nodes):\n",
        "\n",
        "\\[\n",
        "R_\\alpha(T) = R(T) + \\alpha \\cdot |T|\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( R(T) \\) = Training error of the tree \\( T \\)\n",
        "- \\( |T| \\) = Number of terminal nodes (leaves)\n",
        "- \\( \\alpha \\) = Complexity parameter (higher â†’ simpler tree)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example in Scikit-learn\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# First, train a full tree\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Use cost complexity pruning path\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "# Train multiple trees with different alpha values\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n"
      ],
      "metadata": {
        "id": "M3Ki-NQVxDDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10. What is the difference between Pre-Pruning and Post-Pruning\t?"
      ],
      "metadata": {
        "id": "Pdxw9ZOcxKwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‚ï¸ Pre-Pruning vs Post-Pruning in Decision Trees\n",
        "\n",
        "Pruning helps prevent **overfitting** in decision trees by controlling tree complexity. There are two main strategies:\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Key Differences\n",
        "\n",
        "| Feature              | ðŸŸ¢ Pre-Pruning                         | ðŸ”µ Post-Pruning                          |\n",
        "|----------------------|----------------------------------------|------------------------------------------|\n",
        "| **When Applied**      | During tree construction               | After full tree has been built           |\n",
        "| **Also Known As**     | Early Stopping                         | Cost Complexity Pruning (CART)           |\n",
        "| **Working Mechanism** | Stops growth based on pre-defined limits | Grows the full tree, then prunes unnecessary branches |\n",
        "| **Control Parameters**| `max_depth`, `min_samples_split`, etc. | `ccp_alpha` (complexity parameter)       |\n",
        "| **Risk**              | May underfit if too aggressive         | May overfit before pruning, but generally safer |\n",
        "| **Computation Cost**  | Lower (tree is smaller)                | Higher (full tree must be built first)   |\n",
        "| **Flexibility**       | Less flexible â€” relies on heuristics  | More flexible â€” uses validation or cost-based metrics |\n",
        "| **Used In**           | ID3, CART (with parameters)            | CART (`cost_complexity_pruning_path`)    |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Intuition\n",
        "\n",
        "- **Pre-Pruning** prevents the tree from growing too deep by applying constraints early.\n",
        "- **Post-Pruning** trims back parts of the fully-grown tree that are not statistically significant or add complexity with little gain.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§ª Example Use in `scikit-learn`\n",
        "\n",
        "```python\n",
        "# Pre-Pruning\n",
        "DecisionTreeClassifier(max_depth=5, min_samples_split=10)\n",
        "\n",
        "# Post-Pruning\n",
        "DecisionTreeClassifier(ccp_alpha=0.01)\n"
      ],
      "metadata": {
        "id": "IuqvKSDTxQ8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11.  What is a Decision Tree Regressor\t?"
      ],
      "metadata": {
        "id": "WZIVyoUVxdbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ³ðŸ“ˆ Decision Tree Regressor\n",
        "\n",
        "A **Decision Tree Regressor** is a type of decision tree used for **regression tasks**â€”predicting **continuous numerical values** rather than discrete class labels.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Objective\n",
        "\n",
        "To partition the feature space into regions and assign a **predicted value** (usually the **mean** of the target values in that region) for each leaf node.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® How It Works\n",
        "\n",
        "1. The dataset is recursively split based on features that minimize **variance** (instead of classification impurity like Gini/Entropy).\n",
        "2. At each node, the algorithm chooses the **best split** that minimizes the **Mean Squared Error (MSE)** or **Mean Absolute Error (MAE)**.\n",
        "3. The final prediction at a leaf is the **average** of the target values in that leaf.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Mathematical Criterion (MSE)\n",
        "\n",
        "At each node, the algorithm tries to minimize:\n",
        "\n",
        "\\[\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( y_i \\) = Actual values\n",
        "- \\( \\bar{y} \\) = Mean of values in the node\n",
        "- \\( n \\) = Number of samples in the node\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ Example in Scikit-learn\n",
        "\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate regression data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=15, random_state=0)\n",
        "\n",
        "# Train model\n",
        "regressor = DecisionTreeRegressor(max_depth=4)\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# Predict and plot\n",
        "X_test = np.linspace(min(X), max(X), 100).reshape(-1, 1)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "plt.scatter(X, y, color='blue', label='Data')\n",
        "plt.plot(X_test, y_pred, color='red', label='Prediction')\n",
        "plt.title(\"Decision Tree Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vNUW3bB-xjpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q12.  What are the advantages and disadvantages of Decision Trees?"
      ],
      "metadata": {
        "id": "JS--1BY7xtCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ…ðŸ“‰ Advantages and Disadvantages of Decision Trees\n",
        "\n",
        "Decision Trees are popular in machine learning due to their simplicity and interpretability. However, they come with both strengths and limitations.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Advantages\n",
        "\n",
        "1. **Easy to Understand and Interpret**\n",
        "   - Mimics human decision-making with clear rules.\n",
        "\n",
        "2. **No Need for Feature Scaling**\n",
        "   - No normalization or standardization required.\n",
        "\n",
        "3. **Handles Both Numerical and Categorical Data**\n",
        "   - Can work with mixed types of input features.\n",
        "\n",
        "4. **Requires Little Data Preprocessing**\n",
        "   - Handles missing values and irrelevant features reasonably well.\n",
        "\n",
        "5. **Non-Linear Relationships Captured**\n",
        "   - Naturally models complex decision boundaries.\n",
        "\n",
        "6. **Feature Importance**\n",
        "   - Can measure the relative importance of each feature.\n",
        "\n",
        "7. **Works with Multi-output Tasks**\n",
        "   - Can be adapted to predict multiple outputs.\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ Disadvantages\n",
        "\n",
        "1. **Prone to Overfitting**\n",
        "   - Especially with deep trees or noisy data.\n",
        "\n",
        "2. **Unstable**\n",
        "   - Small changes in data can result in a completely different tree.\n",
        "\n",
        "3. **Biased with Imbalanced Data**\n",
        "   - Tends to favor classes with more examples.\n",
        "\n",
        "4. **Greedy Algorithm**\n",
        "   - Makes locally optimal decisions; may not find the global best tree.\n",
        "\n",
        "5. **Not Good at Smooth Predictions**\n",
        "   - Step-like predictions for regression tasks.\n",
        "\n",
        "6. **Can Be Computationally Expensive**\n",
        "   - Very large trees take longer to train and may require pruning.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Tip\n",
        "\n",
        "> ðŸŽ¯ Combine Decision Trees with ensemble methods like **Random Forests** or **Gradient Boosting** to mitigate many of these limitations.\n",
        "\n"
      ],
      "metadata": {
        "id": "xSNL9Ebfxylk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q13.  How does a Decision Tree handle missing values?"
      ],
      "metadata": {
        "id": "mGXrWf0dyGVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# â“ðŸŒ³ How Do Decision Trees Handle Missing Values?\n",
        "\n",
        "Handling missing data is a common challenge in real-world datasets. **Decision Trees** can manage missing values more flexibly than many other machine learning algorithms.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Strategies to Handle Missing Values in Decision Trees\n",
        "\n",
        "### 1. **Ignore Instances with Missing Values**\n",
        "- Simplest strategy (used when missing values are few).\n",
        "- Removes rows with missing data during training.\n",
        "- âš ï¸ Risk of losing useful information.\n",
        "\n",
        "### 2. **Imputation Before Training**\n",
        "- Replace missing values with:\n",
        "  - Mean/Median (for numerical)\n",
        "  - Mode (for categorical)\n",
        "- This is done **before fitting the model**, often with `SimpleImputer` in scikit-learn.\n",
        "\n",
        "```python\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent'\n",
        "X_imputed = imputer.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "M7wMAYBHyLrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q14. How does a Decision Tree handle categorical features?"
      ],
      "metadata": {
        "id": "GMEUKQzJPHEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¤ðŸŒ³ How Do Decision Trees Handle Categorical Features?\n",
        "\n",
        "**Decision Trees** are naturally capable of handling both **numerical** and **categorical** features. However, how they do this depends on the implementation (like `scikit-learn`, `XGBoost`, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ What Are Categorical Features?\n",
        "\n",
        "- Features with **discrete** values (e.g., \"Red\", \"Green\", \"Blue\")\n",
        "- Typically **non-numeric**\n",
        "- Can be **nominal** (no order) or **ordinal** (ordered categories)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  How Decision Trees Handle Categorical Features\n",
        "\n",
        "### 1. **Binary Splits (One-vs-Rest)**\n",
        "- Tree checks if the feature equals a particular category.\n",
        "- Example:\n",
        "  - Feature = \"Color\", Values = {Red, Green, Blue}\n",
        "  - Split: `Color == Red` â†’ True branch, else â†’ False branch\n",
        "\n",
        "### 2. **Multiway Splits (Non-binary trees)**\n",
        "- Each unique category gets its own branch.\n",
        "- More common in some libraries like `CART`, `C4.5`, or `rpart`.\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Handling Categorical Features in Scikit-learn\n",
        "\n",
        "### âŒ Native Limitation\n",
        "- `sklearn.tree.DecisionTreeClassifier` **does not support non-numeric categorical features** directly.\n",
        "- Must convert them using **encoding**:\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Solution: Encode Before Training\n",
        "\n",
        "### **Label Encoding** (if ordinal)\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X['category'] = le.fit_transform(X['category'])\n"
      ],
      "metadata": {
        "id": "jYVYPYMfPTU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q15. What are some real-world applications of Decision Trees?"
      ],
      "metadata": {
        "id": "IwfZ12_kPdsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ Real-World Applications of Decision Trees\n",
        "\n",
        "Decision Trees are widely used in various domains due to their **interpretability**, **low preprocessing**, and ability to handle **both categorical and numerical data**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¦ 1. **Finance**\n",
        "\n",
        "- **Credit Scoring**: Classify applicants as low or high risk.\n",
        "- **Loan Approval**: Determine eligibility based on income, credit history, etc.\n",
        "- **Fraud Detection**: Identify suspicious transactions using rule-based splits.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¥ 2. **Healthcare**\n",
        "\n",
        "- **Medical Diagnosis**: Classify diseases based on symptoms and patient history.\n",
        "- **Risk Assessment**: Predict patient readmission or complication risk.\n",
        "- **Treatment Recommendation**: Suggest treatments based on decision paths.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ›’ 3. **Retail & E-commerce**\n",
        "\n",
        "- **Customer Segmentation**: Group customers based on purchasing behavior.\n",
        "- **Churn Prediction**: Identify customers likely to leave the platform.\n",
        "- **Recommendation Engines**: Suggest products using behavioral patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ“ 4. **Education**\n",
        "\n",
        "- **Student Performance Prediction**: Based on attendance, grades, and participation.\n",
        "- **Dropout Risk Analysis**: Identify students likely to drop out.\n",
        "- **Adaptive Learning Systems**: Customize content based on student progress.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš— 5. **Transportation**\n",
        "\n",
        "- **Traffic Prediction**: Predict congestion levels based on time, location, and weather.\n",
        "- **Route Optimization**: Select shortest/safest routes based on traffic patterns.\n",
        "- **Vehicle Failure Detection**: Classify vehicle component failures.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŒ¾ 6. **Agriculture**\n",
        "\n",
        "- **Crop Disease Diagnosis**: Predict plant diseases from images and environmental data.\n",
        "- **Yield Prediction**: Estimate productivity based on soil, weather, and crop features.\n",
        "- **Irrigation Management**: Optimize water use using decision models.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ•µï¸ 7. **Cybersecurity**\n",
        "\n",
        "- **Intrusion Detection Systems (IDS)**: Classify network traffic as normal or malicious.\n",
        "- **Spam Filtering**: Detect spam based on message features.\n",
        "- **Phishing Detection**: Classify URLs or emails as phishing or safe.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ—³ï¸ 8. **Government & Public Policy**\n",
        "\n",
        "- **Policy Impact Analysis**: Predict effects of policy interventions on target groups.\n",
        "- **Resource Allocation**: Optimize the distribution of welfare schemes.\n",
        "- **Crime Prediction**: Analyze crime data to predict high-risk areas.\n",
        "\n",
        "---\n",
        "\n",
        "> ðŸ’¡ **Tip**: Decision Trees are easy to interpret, making them ideal for fields where transparency and explainability are critical (e.g., healthcare, finance, law).\n"
      ],
      "metadata": {
        "id": "IXdfcvpUPikh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JszboBtAPsIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy?"
      ],
      "metadata": {
        "id": "2WmCzHPPPwx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F37UIC0NP8Ce",
        "outputId": "0d15f25a-d866-41d5-ba61-e7bd3ca7d5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances?"
      ],
      "metadata": {
        "id": "wNhXBZevQNko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X, y)\n",
        "print(\"Feature importances:\", clf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jue-7v1uQZCp",
        "outputId": "137f2255-3ae7-41b8-a107-1710c31ebb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances: [0.01333333 0.         0.56405596 0.42261071]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy?"
      ],
      "metadata": {
        "id": "SlXoCZmUQb93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "clf = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "9vyTH6qiTAEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bea69e-24ca-428d-b7cc-be818b8a0fd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE)?"
      ],
      "metadata": {
        "id": "lZKUH8exUZ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "KLnH0mlwUelm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db2ff43-aa54-440a-80f9-19d8ec63ad6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.5280096503174904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz?"
      ],
      "metadata": {
        "id": "FnMYVPiGU1iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "iris = load_iris()\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(iris.data, iris.target)\n",
        "\n",
        "dot_data = export_graphviz(clf,\n",
        "                           out_file=None,\n",
        "                           feature_names=iris.feature_names,\n",
        "                           class_names=iris.target_names,\n",
        "                           filled=True,\n",
        "                           rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_decision_tree\")\n",
        "graph.view()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gbws16gZU9mE",
        "outputId": "538784bb-eeb2-4398-dc22-36cfe72dfd82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree?"
      ],
      "metadata": {
        "id": "sj6-RRmAVGad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf_max_depth = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "clf_max_depth.fit(X_train, y_train)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "acc_max_depth = accuracy_score(y_test, clf_max_depth.predict(X_test))\n",
        "acc_full = accuracy_score(y_test, clf_full.predict(X_test))\n",
        "\n",
        "print(\"Accuracy with max_depth=3:\", acc_max_depth)\n",
        "print(\"Accuracy with fully grown tree:\", acc_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T2WrwKhVQkF",
        "outputId": "61b95f71-4ef5-4ea4-a0f0-d45a3c761a17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=3: 1.0\n",
            "Accuracy with fully grown tree: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree?"
      ],
      "metadata": {
        "id": "n2yL3nQCVZyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf_default = DecisionTreeClassifier(random_state=42)\n",
        "clf_min_split = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "\n",
        "clf_default.fit(X_train, y_train)\n",
        "clf_min_split.fit(X_train, y_train)\n",
        "\n",
        "acc_default = accuracy_score(y_test, clf_default.predict(X_test))\n",
        "acc_min_split = accuracy_score(y_test, clf_min_split.predict(X_test))\n",
        "\n",
        "print(\"Default Tree Accuracy:\", acc_default)\n",
        "print(\"Tree with min_samples_split=5 Accuracy:\", acc_min_split)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXSda3WvVnhg",
        "outputId": "756db856-98f1-481f-871f-99d46c626764"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Tree Accuracy: 1.0\n",
            "Tree with min_samples_split=5 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data?"
      ],
      "metadata": {
        "id": "riBEr99WVvpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_unscaled.fit(X_train, y_train)\n",
        "pred_unscaled = clf_unscaled.predict(X_test)\n",
        "acc_unscaled = accuracy_score(y_test, pred_unscaled)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "clf_scaled = DecisionTreeClassifier(random_state=42)\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, pred_scaled)\n",
        "\n",
        "print(\"Accuracy with unscaled data:\", acc_unscaled)\n",
        "print(\"Accuracy with scaled data:\", acc_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU4MaZtBWAZx",
        "outputId": "f9865e52-129a-43b7-e65c-9591eb8c4111"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with unscaled data: 1.0\n",
            "Accuracy with scaled data: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification?"
      ],
      "metadata": {
        "id": "7tVk6AJZWHv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "ovr_clf = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "y_pred = ovr_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZow_qu9WQcn",
        "outputId": "008825bc-f56e-4d3a-b8d7-c06ee651690a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores?"
      ],
      "metadata": {
        "id": "B8xcPcRkWVMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X, y)\n",
        "importances = clf.feature_importances_\n",
        "print(\"Feature importance scores:\")\n",
        "for feature, importance in zip(iris.feature_names, importances):\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ElXLvX4WlUl",
        "outputId": "748df443-bc02-475b-ee94-6089c9f057ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance scores:\n",
            "sepal length (cm): 0.013333333333333329\n",
            "sepal width (cm): 0.0\n",
            "petal length (cm): 0.5640559581320451\n",
            "petal width (cm): 0.4226107085346215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree?"
      ],
      "metadata": {
        "id": "xW-Jj8DcWmob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "tree_depth5 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "tree_depth5.fit(X_train, y_train)\n",
        "y_pred_depth5 = tree_depth5.predict(X_test)\n",
        "mse_depth5 = mean_squared_error(y_test, y_pred_depth5)\n",
        "\n",
        "tree_full = DecisionTreeRegressor(random_state=42)\n",
        "tree_full.fit(X_train, y_train)\n",
        "y_pred_full = tree_full.predict(X_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "print(\"MSE with max_depth=5:\", mse_depth5)\n",
        "print(\"MSE with unrestricted tree:\", mse_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0308bXgzW3eD",
        "outputId": "17dba622-17d1-4b17-fb4e-5278b7a60270"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with max_depth=5: 0.5210801561811793\n",
            "MSE with unrestricted tree: 0.5280096503174904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy?"
      ],
      "metadata": {
        "id": "2q3sokLVW78f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "clfs = []\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))\n",
        "    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))\n",
        "    clfs.append(clf)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, train_scores, marker='o', label=\"Train Accuracy\", drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas, test_scores, marker='o', label=\"Test Accuracy\", drawstyle=\"steps-post\")\n",
        "plt.xlabel(\"CCP Alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Effect of Cost Complexity Pruning on Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wKnGGf6ZXCPX",
        "outputId": "caf6ca71-6324-4b82-8ba0-d964171be733"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score?"
      ],
      "metadata": {
        "id": "rZDpuFR_XQsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31O1UcNPXb63",
        "outputId": "9950128d-0529-45ea-e401-9a932ca02e4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn?"
      ],
      "metadata": {
        "id": "7EA7adelXgJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "A9HNKIQVXma2",
        "outputId": "ce3a65cb-4b5b-478a-e399-b2b15e41e8b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split."
      ],
      "metadata": {
        "id": "th0CmoU-YLhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [None, 2, 3, 4, 5, 6],\n",
        "    'min_samples_split': [2, 3, 4, 5, 6]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "print(\"Test set score:\", grid_search.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHFDOPuTYSUG",
        "outputId": "f5e0ec5e-73fe-4108-f469-a37753289398"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'min_samples_split': 6}\n",
            "Best cross-validation score: 0.9428571428571428\n",
            "Test set score: 1.0\n"
          ]
        }
      ]
    }
  ]
}